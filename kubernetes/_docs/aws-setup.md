# Setting up AWS EKS Cluster

Configuring and creating an EKS cluster involves multiple steps, please ensure you follow them rigourously otherwise the cluster creation will not be successfull.

#### Create VPC
First step will be to create a new VPC in AWS console, navigate to the VPC section and create a new VPC.

The VPC configuration should be in the region where you plan to deploy your EKS cluster.

- Choose VPC and More
- Ensure you set up a name for your VPC, so it is easier to find it (instead of autogenerated)
- 2 public subnets is enough, no need of private 
- you do not need S3 gateway or NAT

After creating the subnets, go individually and add a Tag

Tag Name                      Value

| Tag Name               | Value        |
| -----------------------| ------------ |
| kubernetes.io/role/elb |      1       |

Ensure your subnets have ipv4 auto assignment checked in.

## Create EKS Cluster

Ensure you are in the same region as the VPC region you have created in the previous step.

Follow the instructions to create a Cluster Role, this role will be used to ensure the cluster has permissions to create volumes, ec2 instances etc.

https://docs.aws.amazon.com/eks/latest/userguide/service_IAM_role.html#create-service-role

### Setting up the cluster
- Choose a name, ideally something like `foobar-[dev/testnet/prod]`
- Choose the kubernetes version, the most recent should do
- Choose the VPC you have created in order to select the subnets
- Cluster Endpoint access should be public, so you can access and control
- Logging can be left intact, you can enable this in the future if needed

Once your cluster is created, you will need to allocate computing resources for your cluster to use. This is done through the Compute tab.
Navigate to your cluster's Computer tab and click `Add node group`. Name your nodegroup something like `nodegroup1`, select the instances you want to use.

The next step required would be to create an identity provider, follow the steps here https://docs.aws.amazon.com/eks/latest/userguide/enable-iam-roles-for-service-accounts.html

### Configuring your cluster
#### Persistent Volumes Configuration

To create persistent volumes follow Option A https://aws.amazon.com/premiumsupport/knowledge-center/eks-persistent-storage/

    Option A: Deploy and test the Amazon EBS CSI driver

    aws eks describe-cluster --name <cluster name> --query "cluster.identity.oidc.issuer" --output text --region <region>
    aws iam create-role --role-name AmazonEKS_EBS_CSI_DriverRole_<dev/testnet/prod> --assume-role-policy-document file://"trust-policy.json"
    aws iam attach-role-policy --policy-arn arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy  --role-name AmazonEKS_EBS_CSI_DriverRole_<dev/testnet/prod>
    kubectl apply -k "github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/?ref=release-1.15"
    kubectl annotate serviceaccount ebs-csi-controller-sa -n kube-system eks.amazonaws.com/role-arn=arn:aws:iam::618528691313:role/AmazonEKS_EBS_CSI_DriverRole_Prod
    kubectl delete pods -n kube-system -l=app=ebs-csi-controller

#### Load Balancer controller

The full explanation and details about the load balancer are available here https://docs.aws.amazon.com/eks/latest/userguide/aws-load-balancer-controller.html

	aws iam create-role --role-name AmazonEKSLoadBalancerControllerRole<Dev/Prod/Testnet> --assume-role-policy-document file://"load-balancer-role-trust-policy.json"
	aws iam attach-role-policy --policy-arn arn:aws:iam::618528691313:policy/AWSLoadBalancerControllerIAMPolicy --role-name AmazonEKSLoadBalancerControllerRole<Dev/Testnet/Prod>
	kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.11.0/cert-manager.yaml
	curl -Lo v2_4_6_full.yaml https://github.com/kubernetes-sigs/aws-load-balancer-controller/releases/download/v2.4.6/v2_4_6_full.yaml


#### Secrets Manager configuration

It is possible to mount and expose secrets from AWS Secrets Manager directly into the pods, in order to do that you will need to install the following components into the cluster.

	kubectl apply -f https://github.com/kubernetes-sigs/secrets-store-csi-driver/releases/download/v1.3.0/rbac-secretproviderclass.yaml
	kubectl apply -f https://github.com/kubernetes-sigs/secrets-store-csi-driver/releases/download/v1.3.0/csidriver.yaml
	kubectl apply -f https://github.com/kubernetes-sigs/secrets-store-csi-driver/releases/download/v1.3.0/secrets-store.csi.x-k8s.io_secretproviderclasses.yaml
	kubectl apply -f https://github.com/kubernetes-sigs/secrets-store-csi-driver/releases/download/v1.3.0/secrets-store.csi.x-k8s.io_secretproviderclasspodstatuses.yaml
	kubectl apply -f https://github.com/kubernetes-sigs/secrets-store-csi-driver/releases/download/v1.3.0/secrets-store-csi-driver.yaml
	kubectl apply -f https://github.com/kubernetes-sigs/secrets-store-csi-driver/releases/download/v1.3.0/rbac-secretprovidersyncing.yaml
	kubectl apply -f https://raw.githubusercontent.com/aws/secrets-store-csi-driver-provider-aws/main/deployment/aws-provider-installer.yaml

More information of how to use them in your manifests files can be found here https://blog.spikeseed.cloud/handling-aws-secrets-and-parameters-on-eks/

[**warning**] for some reason the secrets objects name cannot be the same so try to use a different name for each environment (dev/testnet/prod)

#### Shipping logs to Cloudwatch

	kubectl apply -f https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/cloudwatch-namespace.yaml

Ensure you changed settings below for the `ClusterName` and `RegionName`

    ClusterName=<cluster-name>
	RegionName=<region>
	FluentBitHttpPort='2020'
	FluentBitReadFromHead='On'
	[[ ${FluentBitReadFromHead} = 'On' ]] && FluentBitReadFromTail='Off'|| FluentBitReadFromTail='On'
	[[ -z ${FluentBitHttpPort} ]] && FluentBitHttpServer='Off' || FluentBitHttpServer='On'
	kubectl create configmap fluent-bit-cluster-info \
	--from-literal=cluster.name=${ClusterName} \
	--from-literal=http.server=${FluentBitHttpServer} \
	--from-literal=http.port=${FluentBitHttpPort} \
	--from-literal=read.head=${FluentBitReadFromHead} \
	--from-literal=read.tail=${FluentBitReadFromTail} \
	--from-literal=logs.region=${RegionName} -n amazon-cloudwatch

	kubectl apply -f https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/fluent-bit/fluent-bit.yaml
	kubectl get pods -n amazon-cloudwatch